#!/usr/bin/env python3
"""
ë¹ ë¥¸ ë¬¸ì œ ì§„ë‹¨ ë„êµ¬
"""
import requests
import urllib.parse
from bs4 import BeautifulSoup

def quick_diagnosis():
    print("ğŸš¨ ê¸´ê¸‰ ì§„ë‹¨: ë„¤ì´ë²„ ëª¨ë°”ì¼ í”Œë ˆì´ìŠ¤ í¬ë¡¤ë§")
    print("=" * 50)
    
    keyword = "ì„œìš¸ ìƒì•” ë§›ì§‘"
    target_shop = "ë§¥ë„ë‚ ë“œìƒì•”DMCì "
    
    # ëª¨ë°”ì¼ í—¤ë”
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1",
        "Accept-Language": "ko-KR,ko;q=0.9",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    }
    
    # URL ìƒì„±
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://m.place.naver.com/search?query={encoded_keyword}"
    
    print(f"ğŸ” ê²€ìƒ‰ì–´: {keyword}")
    print(f"ğŸ¯ ì°¾ëŠ” ìƒì : {target_shop}")
    print(f"ğŸŒ URL: {url}")
    print()
    
    try:
        # ìš”ì²­
        response = requests.get(url, headers=headers, timeout=15)
        print(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨")
            return
        
        # HTML ì €ì¥ (ë¶„ì„ìš©)
        with open("quick_diagnosis.html", "w", encoding="utf-8") as f:
            f.write(response.text)
        print(f"ğŸ’¾ HTML ì €ì¥: quick_diagnosis.html")
        
        # ê¸°ë³¸ ë¶„ì„
        soup = BeautifulSoup(response.text, "html.parser")
        
        # 1. ë§¥ë„ë‚ ë“œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        full_text = soup.get_text()
        mcd_in_page = "ë§¥ë„ë‚ ë“œ" in full_text
        print(f"ğŸŸ ë§¥ë„ë‚ ë“œ í…ìŠ¤íŠ¸ ì¡´ì¬: {mcd_in_page}")
        
        if mcd_in_page:
            # ë§¥ë„ë‚ ë“œê°€ ëª‡ ë²ˆ ë‚˜ì˜¤ëŠ”ì§€
            mcd_count = full_text.count("ë§¥ë„ë‚ ë“œ")
            print(f"   ğŸ“Š ë§¥ë„ë‚ ë“œ ì–¸ê¸‰ íšŸìˆ˜: {mcd_count}ë²ˆ")
            
            # ë§¥ë„ë‚ ë“œ ìƒì•”DMCì ì´ ì •í™•íˆ ìˆëŠ”ì§€
            exact_match = target_shop in full_text
            print(f"   ğŸ¯ ì •í™•í•œ ìƒì ëª… ì¡´ì¬: {exact_match}")
            
            # ìƒì•” ê´€ë ¨ ë§¥ë„ë‚ ë“œ ì°¾ê¸°
            sangam_mcd = "ìƒì•”" in full_text and "ë§¥ë„ë‚ ë“œ" in full_text
            print(f"   ğŸ¢ ìƒì•”+ë§¥ë„ë‚ ë“œ ì¡°í•©: {sangam_mcd}")
        
        # 2. ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„
        print(f"\nğŸ“‹ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„:")
        
        # ëª¨ë“  li íƒœê·¸
        all_lis = soup.find_all("li")
        print(f"   ì „ì²´ li íƒœê·¸: {len(all_lis)}ê°œ")
        
        # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” li
        text_lis = [li for li in all_lis if li.get_text().strip()]
        print(f"   í…ìŠ¤íŠ¸ í¬í•¨ li: {len(text_lis)}ê°œ")
        
        # 3. ê°€ëŠ¥í•œ í”Œë ˆì´ìŠ¤ í•­ëª©ë“¤ ì°¾ê¸°
        print(f"\nğŸª í”Œë ˆì´ìŠ¤ í•­ëª© ë¶„ì„:")
        
        # ë§í¬ê°€ ìˆëŠ” í•­ëª©ë“¤
        place_links = soup.find_all("a", href=lambda href: href and "place" in href)
        print(f"   place ë§í¬: {len(place_links)}ê°œ")
        
        # ìƒìœ„ 10ê°œ í…ìŠ¤íŠ¸ li ë‚´ìš© í™•ì¸
        print(f"\nğŸ“ ìƒìœ„ í…ìŠ¤íŠ¸ li ë‚´ìš©:")
        for i, li in enumerate(text_lis[:10]):
            text = li.get_text().strip()[:30]  # 30ê¸€ìë§Œ
            print(f"   {i+1:2d}. {text}...")
        
        # 4. ì‹¤ì œ ë¬¸ì œ ì§„ë‹¨
        print(f"\nğŸ” ë¬¸ì œ ì§„ë‹¨:")
        
        if not mcd_in_page:
            print("   âŒ ë¬¸ì œ 1: ë§¥ë„ë‚ ë“œê°€ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ìŒ")
            print("      â†’ í‚¤ì›Œë“œë‚˜ ê²€ìƒ‰ ë°©ì‹ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ")
        
        if len(text_lis) == 0:
            print("   âŒ ë¬¸ì œ 2: ë¦¬ìŠ¤íŠ¸ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            print("      â†’ HTML êµ¬ì¡°ë‚˜ ì„ íƒì ë¬¸ì œ")
        
        if len(place_links) == 0:
            print("   âŒ ë¬¸ì œ 3: í”Œë ˆì´ìŠ¤ ë§í¬ê°€ ì—†ìŒ")
            print("      â†’ í˜ì´ì§€ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„")
        
        # 5. í•´ê²° ë°©í–¥ ì œì‹œ
        print(f"\nğŸ’¡ í•´ê²° ë°©í–¥:")
        if not mcd_in_page:
            print("   1. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ í…ŒìŠ¤íŠ¸ (ì˜ˆ: 'ìƒì•”ë™ ë§›ì§‘', 'ìƒì•” í–„ë²„ê±°')")
            print("   2. ë°ìŠ¤í¬í†± ë²„ì „ê³¼ ë¹„êµ")
        
        if len(text_lis) == 0:
            print("   3. HTML íŒŒì¼ì„ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ ì‹¤ì œ êµ¬ì¡° í™•ì¸")
            print("   4. ë„¤ì´ë²„ ëª¨ë°”ì¼ ì‚¬ì´íŠ¸ ì§ì ‘ ë°©ë¬¸í•˜ì—¬ ë¹„êµ")
            
    except Exception as e:
        print(f"âŒ ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    quick_diagnosis()