#!/usr/bin/env python3
"""
2025ë…„ 5ì›” ì—…ë°ì´íŠ¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ìµœì‹  ì…€ë ‰í„° í…ŒìŠ¤íŠ¸
- IP ë¡œí…Œì´ì…˜ í…ŒìŠ¤íŠ¸  
- CAPTCHA ê°ì§€ í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
"""
import os
import sys
import json
import time
from datetime import datetime
import logging

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_2025_updated_crawler():
    """2025ë…„ 5ì›” ì—…ë°ì´íŠ¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ 2025ë…„ 5ì›” ì—…ë°ì´íŠ¸ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from updated_naver_crawler_2025 import Updated2025NaverCrawler
        from proxy_manager import ProxyManager, create_proxy_list_from_config
        
        # í”„ë¡ì‹œ ì„¤ì •
        proxy_list = create_proxy_list_from_config()
        use_proxy = len(proxy_list) > 0
        
        if use_proxy:
            print(f"ğŸ“¡ í”„ë¡ì‹œ {len(proxy_list)}ê°œ ê°ì§€ë¨")
            proxy_manager = ProxyManager(proxy_list)
            working_proxies = proxy_manager.test_all_proxies()
            print(f"âœ… ì‘ë™í•˜ëŠ” í”„ë¡ì‹œ: {len(working_proxies)}ê°œ")
        else:
            print("âš ï¸  í”„ë¡ì‹œ ì—†ì´ í…ŒìŠ¤íŠ¸ ì§„í–‰ (CAPTCHA ìœ„í—˜ ë†’ìŒ)")
        
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = Updated2025NaverCrawler(
            headless=False,  # ë””ë²„ê¹…ì„ ìœ„í•´ ë¸Œë¼ìš°ì € í‘œì‹œ
            delay_range=(3, 8),
            use_proxy=use_proxy,
            proxy_list=proxy_list
        )
        
        print("âœ… í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì„±ê³µ")
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤ (2025ë…„ 5ì›” ê¸°ì¤€)
        test_cases = [
            {
                "keyword": "ì„œìš¸ ìƒì•” ë§›ì§‘",
                "shop_name": "ë§¥ë„ë‚ ë“œìƒì•”DMCì ",
                "description": "ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤",
                "expected_rank_range": (1, 30)
            },
            {
                "keyword": "ê°•ë‚¨ ì¹´í˜",
                "shop_name": "ìŠ¤íƒ€ë²…ìŠ¤",
                "description": "ì¼ë°˜ì ì¸ ë¸Œëœë“œ ê²€ìƒ‰",
                "expected_rank_range": (1, 20)
            },
            {
                "keyword": "í™ëŒ€ ì¹˜í‚¨",
                "shop_name": "êµì´Œì¹˜í‚¨",
                "description": "í”„ëœì°¨ì´ì¦ˆ ê²€ìƒ‰",
                "expected_rank_range": (1, 15)
            }
        ]
        
        results = []
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}/{len(test_cases)}: {test_case['description']}")
            print(f"   í‚¤ì›Œë“œ: {test_case['keyword']}")
            print(f"   ì°¾ëŠ” ìƒì : {test_case['shop_name']}")
            
            start_time = time.time()
            
            try:
                result = crawler.search_place_rank(
                    test_case['keyword'], 
                    test_case['shop_name']
                )
                
                end_time = time.time()
                elapsed = end_time - start_time
                
                print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
                print(f"   ğŸ”¢ ìš”ì²­ íšŸìˆ˜: {result.get('request_count', 'N/A')}")
                print(f"   âœ… ì„±ê³µ: {result['success']}")
                print(f"   ğŸ† ìˆœìœ„: {result['rank']}")
                print(f"   ğŸ’¬ ë©”ì‹œì§€: {result['message']}")
                
                # CAPTCHA ê°ì§€ í™•ì¸
                if "CAPTCHA detected" in result.get('message', ''):
                    print("   ğŸš¨ CAPTCHA ê°ì§€ë¨!")
                
                if result['found_shops']:
                    print(f"   ğŸ“ ë°œê²¬ëœ ìƒì ë“¤ (ìƒìœ„ 5ê°œ):")
                    for j, shop in enumerate(result['found_shops'][:5], 1):
                        print(f"      {j}. {shop}")
                
                # ê²°ê³¼ ì €ì¥
                test_result = {
                    "test_case": i,
                    "keyword": test_case['keyword'],
                    "shop_name": test_case['shop_name'],
                    "description": test_case['description'],
                    "success": result['success'],
                    "rank": result['rank'],
                    "elapsed_time": elapsed,
                    "request_count": result.get('request_count', 0),
                    "found_shops_count": len(result['found_shops']),
                    "message": result['message'],
                    "captcha_detected": "CAPTCHA detected" in result.get('message', '')
                }
                results.append(test_result)
                
                # ì„±ê³µë¥  í‰ê°€
                if result['success']:
                    expected_min, expected_max = test_case['expected_rank_range']
                    if expected_min <= result['rank'] <= expected_max:
                        print(f"   ğŸ¯ ì˜ˆìƒ ìˆœìœ„ ë²”ìœ„ ë‚´ ({expected_min}-{expected_max}ìœ„)")
                    else:
                        print(f"   âš ï¸  ì˜ˆìƒ ìˆœìœ„ ë²”ìœ„ ë°– (ì˜ˆìƒ: {expected_min}-{expected_max}ìœ„)")
                else:
                    print(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨")
                
            except Exception as e:
                print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                test_result = {
                    "test_case": i,
                    "keyword": test_case['keyword'],
                    "shop_name": test_case['shop_name'],
                    "description": test_case['description'],
                    "success": False,
                    "error": str(e),
                    "elapsed_time": time.time() - start_time
                }
                results.append(test_result)
            
            # í…ŒìŠ¤íŠ¸ ê°„ ì§€ì—° (CAPTCHA ë°©ì§€)
            if i < len(test_cases):
                wait_time = 10
                print(f"   ğŸ’¤ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ê¹Œì§€ {wait_time}ì´ˆ ëŒ€ê¸° (CAPTCHA ë°©ì§€)...")
                time.sleep(wait_time)
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        analyze_test_results(results, use_proxy)
        
        # ê²°ê³¼ ì €ì¥
        save_test_results(results, use_proxy)
        
    except ImportError as e:
        print(f"âŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install -r requirements_selenium.txt")
    
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        try:
            if 'crawler' in locals():
                crawler.close()
                print("ğŸ”’ í¬ë¡¤ëŸ¬ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except:
            pass

def analyze_test_results(results, use_proxy):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
    print("=" * 50)
    
    total_tests = len(results)
    successful_tests = sum(1 for r in results if r.get('success', False))
    captcha_detected = sum(1 for r in results if r.get('captcha_detected', False))
    
    success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
    print(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}ê°œ")
    print(f"ì„±ê³µë¥ : {success_rate:.1f}%")
    print(f"CAPTCHA ê°ì§€: {captcha_detected}ê°œ")
    
    if successful_tests > 0:
        successful_results = [r for r in results if r.get('success', False)]
        avg_time = sum(r.get('elapsed_time', 0) for r in successful_results) / len(successful_results)
        avg_rank = sum(r.get('rank', 0) for r in successful_results) / len(successful_results)
        total_requests = sum(r.get('request_count', 0) for r in results)
        
        print(f"í‰ê·  ì†Œìš” ì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"í‰ê·  ìˆœìœ„: {avg_rank:.1f}ìœ„")
        print(f"ì´ ìš”ì²­ ìˆ˜: {total_requests}ê°œ")
    
    # í”„ë¡ì‹œ ì‚¬ìš© í‰ê°€
    if use_proxy:
        print(f"ğŸŒ í”„ë¡ì‹œ ì‚¬ìš©: í™œì„±í™”")
        if captcha_detected == 0:
            print("   âœ… CAPTCHA íšŒí”¼ ì„±ê³µ")
        else:
            print("   âš ï¸  CAPTCHA ì¼ë¶€ ê°ì§€ë¨ - í”„ë¡ì‹œ ë¡œí…Œì´ì…˜ í•„ìš”")
    else:
        print(f"ğŸŒ í”„ë¡ì‹œ ì‚¬ìš©: ë¹„í™œì„±í™”")
        if captcha_detected > 0:
            print("   ğŸš¨ CAPTCHA ê°ì§€ë¨ - í”„ë¡ì‹œ ì‚¬ìš© ê¶Œì¥")
    
    # ìµœì¢… í‰ê°€
    if success_rate >= 80 and captcha_detected == 0:
        print("ğŸ‰ í¬ë¡¤ëŸ¬ê°€ ìš°ìˆ˜í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤!")
        recommendation = "production_ready"
    elif success_rate >= 60:
        print("âš ï¸  í¬ë¡¤ëŸ¬ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ê°œì„  ê¶Œì¥.")
        recommendation = "needs_improvement"
    else:
        print("âŒ í¬ë¡¤ëŸ¬ì— ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        recommendation = "needs_major_fixes"
    
    # êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­
    print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    if captcha_detected > 0:
        print("   - í”„ë¡ì‹œ ë¡œí…Œì´ì…˜ í™œì„±í™”")
        print("   - ìš”ì²­ ê°„ê²© ì¦ê°€ (15-30ì´ˆ)")
        print("   - ì¼ì¼ ìš”ì²­ ì œí•œ ì¤€ìˆ˜ (400ê°œ/IP)")
    
    if success_rate < 80:
        print("   - ì…€ë ‰í„° ì—…ë°ì´íŠ¸ í™•ì¸")
        print("   - ë„¤ì´ë²„ í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ ì ê²€")
        print("   - ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ë¡œ ìˆ˜ë™ í™•ì¸")
    
    return recommendation

def save_test_results(results, use_proxy):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"test_results_2025_{timestamp}.json"
    
    summary = {
        "test_date": datetime.now().isoformat(),
        "crawler_version": "2025_may_update",
        "proxy_enabled": use_proxy,
        "total_tests": len(results),
        "successful_tests": sum(1 for r in results if r.get('success', False)),
        "captcha_detected": sum(1 for r in results if r.get('captcha_detected', False)),
        "results": results
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def test_selector_update():
    """2025ë…„ 5ì›” ì…€ë ‰í„° ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” 2025ë…„ 5ì›” ì…€ë ‰í„° ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        import time
        
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15')
        
        driver = webdriver.Chrome(options=options)
        
        try:
            url = "https://m.search.naver.com/search.naver?where=m&query=ì„œìš¸ ìƒì•” ë§›ì§‘"
            driver.get(url)
            time.sleep(5)
            
            # 2025ë…„ 5ì›” ì—…ë°ì´íŠ¸ëœ ì…€ë ‰í„°ë“¤ í…ŒìŠ¤íŠ¸
            selectors_to_test = [
                ('li[data-nclick*="plc"]', '2025ë…„ 5ì›” ë©”ì¸ ì…€ë ‰í„°'),
                ('li.place_unit', 'ê¸°ì¡´ ì…€ë ‰í„°'),
                ('li[data-place-id]', 'ë°±ì—… ì…€ë ‰í„° 1'),
                ('ul.list_place li', 'ë°±ì—… ì…€ë ‰í„° 2')
            ]
            
            print("ì…€ë ‰í„° í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            for selector, description in selectors_to_test:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    text_elements = [el for el in elements if el.text.strip()]
                    
                    status = "âœ…" if len(text_elements) > 0 else "âŒ"
                    print(f"   {status} {selector:25} ({description:20}): {len(elements):3d}ê°œ (í…ìŠ¤íŠ¸: {len(text_elements):3d}ê°œ)")
                    
                    if len(text_elements) > 0:
                        print(f"      ìƒ˜í”Œ: {text_elements[0].text[:50]}...")
                        
                except Exception as e:
                    print(f"   âŒ {selector:25}: ì˜¤ë¥˜ - {e}")
            
        finally:
            driver.quit()
            
    except Exception as e:
        print(f"âŒ ì…€ë ‰í„° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    print("ğŸ§ª 2025ë…„ 5ì›” ì—…ë°ì´íŠ¸ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['CRAWLER_MODE'] = 'test'
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # ì…€ë ‰í„° ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
    test_selector_update()
    
    # ë©”ì¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
    test_2025_updated_crawler()
    
    print(f"\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"â° ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    print("2. CAPTCHAê°€ ê°ì§€ë˜ë©´ í”„ë¡ì‹œë¥¼ ì„¤ì •í•˜ì„¸ìš”")
    print("3. ì„±ê³µë¥ ì´ ë‚®ìœ¼ë©´ ì…€ë ‰í„°ë¥¼ ì¬í™•ì¸í•˜ì„¸ìš”")
    print("4. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” headless=Trueë¡œ ì‹¤í–‰í•˜ì„¸ìš”")